---
layout:     post
title:      秒开优化
subtitle:   
date:       2020-01-05
author:     Glen
header-img: img/post-bg-none.jpg
catalog: true
tags:
    - 秒开
    - 音视频
---

​	在一个直播App中，观众端最直观的体验就是首屏时间的时长。首屏时间指的是从观众点击一个房间开始，到看到这个房间内主播的画面以及听到主播声音的时间。首屏时间越短，产品越流畅，体验也越好。因此，如何缩短首屏时间成为一个直播App必须持续优化的问题。

​	首先来看拉流播放器的整体架构图：![1588493416285](C:\Users\wjy\AppData\Local\Temp\1588493416285.png)

​	最左边是VideoOutput和AudioOutput模块，其内部由自己维护线程来渲染视频画面与音频数据，整个播放流程是由AudioOutput来驱动的，当AudioOutput播放一帧音频帧时，就会向VideoPlayerController中audioCallback方法发出请求，让它来填充音频数据。待填充好音频数据之后，就发送一个指令给VideoOutput模块，让它来渲染视频画面；当VideoOutput接收到这个指令之后，会向VideoPlayerController中的videoCallback方法发出请求，拿一帧与当前播放的音频帧对齐的画面，然后进行渲染。最右侧是Input模块，负责协议解析，解封装，最终使用软件或者硬件解码器将音视频流解析为原始的格式，而它的客户端代码就是AVSync模块。AVSync模块是为了做音视频同步的，但是，首先它得维护一个线程和音视频队列，并负责调用Input模块将视频流最终解码成为音视频的原始数据，然后放入两个队列中，以便向外提供获取音频数据的方法和获取视频帧的方法，其中音视频同步策略放在获取视频帧的方法中；而VideoPlayerController就是核心控制器类，会控制AudioOutput模块、VideoOutput模块、AVSync模块等所有组件的生命周期。这就是整个播放器的流程，下面就对照这个架构图来分析如何在整个流程中加快首屏时间。

​	首先，要尽快让Input模块完成find_stream_info过程，否则永远不会进入后续的解码过程甚至后续的渲染过程，也就不可能让用户听到声音和看到画面了。所以要对FFmpeg的AVFormatContext设置如下参数：

```
AVFormatContext* pFormatCtx;
pFormatCtx->max_analyze_duration = 20 * 1024;
pFormatCtx->probesize = 2048;
pFormatCtx->fps_probe_size = 3;
```

​	当然，设置这些参数加快了f ind_stream_info方法的执行时间，但是有可能（概率比较低）导致解析出来的流没有正确的信息，所以需要重试机制，来解决这种异常情况。这个设置也是直播播放器与录播播放器不同的地方，由于录播视频进行播放时肯定从第一帧视频帧展示给用户，而第一帧又是关键帧，所以可以很快解码出视频帧；而对于直播的视频，拉流播放器不一定在哪一帧连接上来，所以需要客户端和CDN厂商做优化，CDN厂商会缓存关键帧，尽量快地把关键帧给到拉流播放器。

​	然后要尽快启动播放器，当观众端点击某个主播的房间时就调用播放器的init方法，而页面的跳转也需要100ms到500ms的时间（实际场景中可能会是一个动画）。当跳转页面完成的时候，播放器早已完成了初始化和解码前几帧视频帧的工作，直接可以进行渲染了。但是在这种场景下，需要播放器具备一种特性，即没有页面也可以播放视频中的音频，如果播放器现在不支持，则需要改进成这种结构，因为这种结构对于后续的扩展（比如小窗播放器等功能）是非常有益的。由于目前VideoOutput组件的初始化被耦合到VideoPlayerController的Init方法中，所以要将VideoOutput组件的初始化与整个播放器的初始化分开。

**Android平台播放器的预加载**

​	在Android平台显示部分使用的是SurfaceView，依靠SurfaceView设置的Callback中的生命周期方法，将Surface传递到Native层构造出ANativeWindow，然后构建成为EGLDisplay，最终由OpenGL ES渲染上去。之前的播放器初始化也是由SurfaceView设置的Callback中的生命周期方法onSurfaceCreate来触发的，而此次要改造播放器的最终结构，并脱离SurfaceView的生命周期控制。

​	首先在VideoPlayerController公布init接口方法：

```
bool init(char* url, JavaVM* g_jvm, jobject obj);
```

​	这个方法的实现开辟了一个新线程，并在这个线程中实例化AVSync后调用初始化方法来打开流，如果成功，则实例化AudioOutput并调用start方法让声音开始播放，然后回调客户端代码表示已经成功打开了流。声音播放自然会回调设置给AudioOutput的回调函数来填充音频数据，而这个填充音频数据的方法就会调用AVSync模块来填充音频数据，同时判断如果videoOutput还没有被设置的话，则不调用videoOutput的signalFrameAvailable方法，这时虽然还完全没有SurfaceView的参与，但播放器已经可以播放视频中的音频部分，代码如下：

```
int VideoPlayerController::consumeAudioFrames(byte* outData, size_t bufferSize) {
    int ret = bufferSize;
    if(this->isPlaying && synchronizer && !synchronizer->isDestroyed && !synchronizer->isPlayCompleted()) {
        ret = synchronizer->fillAudioData(outData, bufferSize);
        signalOutputFrameAvailable();
    } else {
        LOGI("VideoPlayerController::consumeAudioFrames set 0");
        memset(outData, 0, bufferSize);
    }
    return ret;
}
```

​	当客户端发生了页面跳转，并且SurfaceView已经显示出来的时候，Callback的生命周期方法onSurfaceCreate就会被触发，此时客户端调用VideoPlayerController中的onSurface-Create方法，方法实现如下：

```
void VideoPlayerController::onSurfaceCreated(ANativeWindow* window, int width, int height) {
    LOGI("enter VideoPlayerController::onSurfaceCreated...");

    if (window != NULL){
        this->window = window;
    }

    if (userCancelled){
        return;
    }

    if (width > 0 && height > 0){
        this->screenHeight = height;
        this->screenWidth = width;
    }
    if (!videoOutput) {
        initVideoOutput(window);
    }else{
        videoOutput->onSurfaceCreated(window);
    }
    LOGI("Leave VideoPlayerController::onSurfaceCreated...");
}
```

​	如果是第一次进入，则会构建出VideoOutput类型的实例。VideoOutput也会分为两部分：第一部分是构造VideoOutput的OpenGL ES上下文与渲染线程，当然创建OpenGL上下文的时候一定要与Input模块的Uploader共享OpenGL ES上下文；第二部分是根据ANative-Window构造出要渲染的EGLDisplay类型的目标。在VideoOutput中，onSurfaceCreated方法就是用来创建渲染目标EGLDisplay的。如果Activity跳转到了别的子页面（比如充值页面）, SurfaceView也自然会消失，这时Callback的生命周期方法onSurfaceDestroyed会被触发，客户端应该调用VideoPlayer-Controller中的onSurfaceDestroyed方法，方法实现如下：

```
void VideoPlayerController::onSurfaceDestroyed() {
    LOGI("enter VideoPlayerController::onSurfaceDestroyed...");
    if (videoOutput) {
        videoOutput->onSurfaceDestroyed();
    }
}
```

​	这里VideoOutput公布的onSurfaceDestroyed方法是销毁在onSurfaceCreated方法中构造的Renderer、EGLDisplay和根据SurfaceView中的Surface构建的ANativeWindow。注意这个方法并不会销毁OpenGL ES上下文与渲染线程，而VideoOutput提供的stop方法才是彻底销毁VideoOutput这个实例，也只有在这个播放器完全销毁的时候，才会调用VideoOutput的stop方法。

​	最终我们将播放器改造成了一个预加载的播放器，同时也脱离了显示界面的控制，而由自己的生命周期方法来控制播放器状态，使得客户端调用更加方便，同时也为后续小窗口播放器或者后台播放器提供了基础架构。