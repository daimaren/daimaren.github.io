---
layout:     post
title:      音视频基础
subtitle:   
date:       2020-04-17
author:     Glen
header-img: img/post-bg-none.jpg
catalog: true
tags:
    - x
    - x
    - x
---

对于视频帧的裸数据表示，其实更多的是YUV数据格式的表示，YUV主要应用于优化彩色视频信号的传输，使其向后兼容老式黑白电视。与RGB视频信号传输相比，它最大的优点在于只需要占用极少的频宽（RGB要求三个独立的视频信号同时传输）。其中“Y”表示明亮度（Luminance或Luma），也称灰阶值；而“U”和“V”表示的则是色度（Chrominance或Chroma），它们的作用是描述影像的色彩及饱和度，用于指定像素的颜色。“亮度”是透过RGB输入信号来建立的，方法是将RGB信号的特定部分叠加到一起。“色度”则定义了颜色的两个方面——色调与饱和度，分别用Cr和Cb来表示。其中，Cr反映了RGB输入信号红色部分与RGB信号亮度值之间的差异，而Cb反映的则是RGB输入信号蓝色部分与RGB信号亮度值之间的差异。

之所以采用YUV色彩空间，是因为它的亮度信号Y和色度信号U、V是分离的。如果只有Y信号分量而没有U、V分量，那么这样表示的图像就是黑白灰度图像。彩色电视采用YUV空间正是为了用亮度信号Y解决彩色电视机与黑白电视机的兼容问题，使黑白电视机也能接收彩色电视信号，最常用的表示形式是Y、U、V都使用8个字节来表示，所以取值范围就是0～255。在广播电视系统中不传输很低和很高的数值，实际上是为了防止信号变动造成过载，因而把这“两边”的数值作为“保护带”，不论是Rec.601还是BT.709的广播电视标准中，Y的取值范围都是16～235, UV的取值范围都是16～240。

**视频编码**

使用帧间编码技术可以去除时间上的冗余信息，具体包括以下几个部分。

运动补偿：运动补偿是通过先前的局部图像来预测、补偿当前的局部图像，它是减少帧序列冗余信息的有效方法。运动表示：不同区域的图像需要使用不同的运动矢量来描述运动信息。

运动估计：运动估计是从视频序列中抽取运动信息的一整套技术。

使用帧内编码技术可以去除空间上的冗余信息。

对于视频，ISO同样也制定了标准：Motion JPEG即MPEG, MPEG算法是适用于动态视频的压缩算法，它除了对单幅图像进行编码外，还利用图像序列中的相关原则去除冗余，这样可以大大提高视频的压缩比。截至目前，MPEG的版本一直在不断更新中，主要包括这样几个版本：Mpeg1（用于VCD）、Mpeg2（用于DVD）、Mpeg4AVC（现在流媒体使用最多的就是它了）。

相比较于ISO制定的MPEG的视频压缩标准，ITU-T制定的H.261、H.262、H.263、H.264一系列视频编码标准是一套单独的体系。其中，H.264集中了以往标准的所有优点，并吸取了以往标准的经验，采用的是简洁设计，这使得它比Mpeg4更容易推广。现在使用最多的就是H.264标准，H.264创造了多参考帧、多块类型、整数变换、帧内预测等新的压缩技术，使用了更精细的分像素运动矢量（1/4、1/8）和新一代的环路滤波器，这使得压缩性能得到大大提高，系统也变得更加完善。

**编码概念**

**IPB帧**

视频压缩中，每帧都代表着一幅静止的图像。而在进行实际压缩时，会采取各种算法以减少数据的容量，其中IPB帧就是最常见的一种。

I帧：帧内编码帧（intra picture）, I帧通常是每个GOP（MPEG所使用的一种视频压缩技术）的第一个帧，经过适度地压缩，作为随机访问的参考点，可以当成静态图像。I帧可以看作一个图像经过压缩后的产物，I帧压缩可以得到6:1的压缩比而不会产生任何可觉察的模糊现象。I帧压缩可去掉视频的空间冗余信息，下面即将介绍的P帧和B帧是为了去掉时间冗余信息。

P帧：前向预测编码帧（predictive-frame），通过将图像序列中前面已编码帧的时间冗余信息充分去除来压缩传输数据量的编码图像，也称为预测帧。

B帧：双向预测内插编码帧（bi-directional interpolated prediction frame），既考虑源图像序列前面的已编码帧，又顾及源图像序列后面的已编码帧之间的时间冗余信息，来压缩传输数据量的编码图像，也称为双向预测帧。

基于上面的定义，我们可以从解码的角度来理解IPB帧。

I帧自身可以通过视频解压算法解压成一张单独的完整视频画面，所以I帧去掉的是视频帧在空间维度上的冗余信息。

P帧需要参考其前面的一个I帧或者P帧来解码成一张完整的视频画面。

B帧则需要参考其前一个I帧或者P帧及其后面的一个P帧来生成一张完整的视频画面，所以P帧与B帧去掉的是视频帧在时间维度上的冗余信息。

**IDR帧与I帧的理解**

在H264的概念中有一个帧称为IDR帧，那么IDR帧与I帧的区别是什么呢？首先来看一下IDR的英文全称instantaneous decoding refresh picture，因为H264采用了多帧预测，所以I帧之后的P帧有可能会参考I帧之前的帧，这就使得在随机访问的时候不能以找到I帧作为参考条件，因为即使找到I帧，I帧之后的帧还是有可能解析不出来，而IDR帧就是一种特殊的I帧，即这一帧之后的所有参考帧只会参考到这个IDR帧，而不会再参考前面的帧。在解码器中，一旦收到一个IDR帧，就会立即清理参考帧缓冲区，并将IDR帧作为被参考的帧。

**PTS与DTS**

DTS主要用于视频的解码，英文全称是Decoding Time Stamp, PTS主要用于在解码阶段进行视频的同步和输出，全称是Presentation Time Stamp。在没有B帧的情况下，DTS和PTS的输出顺序是一样的。因为B帧打乱了解码和显示的顺序，所以一旦存在B帧，PTS与DTS势必就会不同，本书后边的章节里会详细讲解如何结合硬件编码器来重新设置PTS和DTS的值，以便将硬件编码器和FFmpeg结合起来使用。这里先简单介绍一下FFmpeg中使用的PTS和DTS的概念，FFmpeg中使用AVPacket结构体来描述解码前或编码后的压缩数据，用AVFrame结构体来描述解码后或编码前的原始数据。对于视频来说，AVFrame就是视频的一帧图像，这帧图像什么时候显示给用户，取决于它的PTS。DTS是AVPacket里的一个成员，表示该压缩包应该在什么时候被解码，如果视频里各帧的编码是按输入顺序（显示顺序）依次进行的，那么解码和显示时间应该是一致的，但是事实上，在大多数编解码标准（如H.264或HEVC）中，编码顺序和输入顺序并不一致，于是才会需要PTS和DTS这两种不同的时间戳。

**GOP的概念**

两个I帧之间形成的一组图片，就是GOP（Group Of Picture）的概念。通常在为编码器设置参数的时候，必须要设置gop_size的值，其代表的是两个I帧之间的帧数目。前面已经讲解过，一个GOP中容量最大的帧就是I帧，所以相对来讲，gop_size设置得越大，整个画面的质量就会越好，但是在解码端必须从接收到的第一个I帧开始才可以正确解码出原始图像，否则会无法正确解码（这也是前面提到的I帧可以作为随机访问的帧）。在提高视频质量的技巧中，还有个技巧是多使用B帧，一般来说，I的压缩率是7（与JPG差不多）, P是20, B可以达到50，可见使用B帧能节省大量空间，节省出来的空间可以用来更多地保存I帧，这样就能在相同的码率下提供更好的画质。所以我们要根据不同的业务场景，适当地设置gop_size的大小，以得到更高质量的视频。

![1588473184660](C:\Users\wjy\AppData\Local\Temp\1588473184660.png)